{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0310ea3f-39d4-4522-bfd2-303c8c76fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import src.models.mlp.mlp_cv_trainer_emb as cv\n",
    "import src.utils.optuna_visualizer as opv\n",
    "import src.utils.telegram as te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0483e9a2-ecc5-4078-a62a-31ab26efcca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "env_path = Path.cwd().parent / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "url = os.environ.get(\"OPTUNA_STORAGE_URL\")\n",
    "\n",
    "tr_df8 = pd.read_parquet(\"../artifacts/features/base/tr_df8.parquet\")\n",
    "test_df8 = pd.read_parquet(\"../artifacts/features/base/test_df8.parquet\")\n",
    "l1_tr_df3 = pd.read_parquet(\"../artifacts/features/l1/l1_tr_df3.parquet\")\n",
    "l1_test_df3 = pd.read_parquet(\"../artifacts/features/l1/l1_tr_df3.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73f1cb74-d86d-4622-810a-ef5a4b6353a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Logloss = 0.29428, Val Logloss = 0.29423\n",
      "New best model saved at epoch 1, Logloss: 0.29423\n",
      "Epoch 2: Train Logloss = 0.25016, Val Logloss = 0.27118\n",
      "New best model saved at epoch 2, Logloss: 0.27118\n",
      "Epoch 3: Train Logloss = 0.22516, Val Logloss = 0.23623\n",
      "New best model saved at epoch 3, Logloss: 0.23623\n",
      "Epoch 4: Train Logloss = 0.18294, Val Logloss = 0.19481\n",
      "New best model saved at epoch 4, Logloss: 0.19481\n",
      "Epoch 5: Train Logloss = 0.17506, Val Logloss = 0.19016\n",
      "New best model saved at epoch 5, Logloss: 0.19016\n",
      "Epoch 6: Train Logloss = 0.17628, Val Logloss = 0.19440\n",
      "Epoch 7: Train Logloss = 0.16680, Val Logloss = 0.18559\n",
      "New best model saved at epoch 7, Logloss: 0.18559\n",
      "Epoch 8: Train Logloss = 0.16454, Val Logloss = 0.18544\n",
      "New best model saved at epoch 8, Logloss: 0.18544\n",
      "Epoch 9: Train Logloss = 0.16185, Val Logloss = 0.18947\n",
      "Epoch 10: Train Logloss = 0.15903, Val Logloss = 0.18800\n",
      "Epoch 11: Train Logloss = 0.15694, Val Logloss = 0.18342\n",
      "New best model saved at epoch 11, Logloss: 0.18342\n",
      "Epoch 12: Train Logloss = 0.15133, Val Logloss = 0.18714\n",
      "Epoch 13: Train Logloss = 0.14904, Val Logloss = 0.18659\n",
      "Epoch 14: Train Logloss = 0.15162, Val Logloss = 0.19407\n",
      "Epoch 15: Train Logloss = 0.14539, Val Logloss = 0.19633\n",
      "Epoch 16: Train Logloss = 0.14443, Val Logloss = 0.19788\n",
      "Epoch 17: Train Logloss = 0.14255, Val Logloss = 0.20055\n",
      "Epoch 18: Train Logloss = 0.13721, Val Logloss = 0.19519\n",
      "Epoch 19: Train Logloss = 0.13813, Val Logloss = 0.20546\n",
      "Epoch 20: Train Logloss = 0.13412, Val Logloss = 0.20507\n",
      "Epoch 21: Train Logloss = 0.13368, Val Logloss = 0.20326\n",
      "Epoch 22: Train Logloss = 0.12798, Val Logloss = 0.20051\n",
      "Epoch 23: Train Logloss = 0.12427, Val Logloss = 0.20566\n",
      "Epoch 24: Train Logloss = 0.12273, Val Logloss = 0.21647\n",
      "Epoch 25: Train Logloss = 0.11935, Val Logloss = 0.21590\n",
      "Epoch 26: Train Logloss = 0.11826, Val Logloss = 0.21274\n",
      "Epoch 27: Train Logloss = 0.11531, Val Logloss = 0.21948\n",
      "Epoch 28: Train Logloss = 0.11290, Val Logloss = 0.22092\n",
      "Epoch 29: Train Logloss = 0.11356, Val Logloss = 0.21583\n",
      "Epoch 30: Train Logloss = 0.10946, Val Logloss = 0.21995\n",
      "Epoch 31: Train Logloss = 0.10722, Val Logloss = 0.22021\n",
      "Epoch 32: Train Logloss = 0.10485, Val Logloss = 0.21679\n",
      "Epoch 33: Train Logloss = 0.10205, Val Logloss = 0.22452\n",
      "Epoch 34: Train Logloss = 0.10128, Val Logloss = 0.22594\n",
      "Epoch 35: Train Logloss = 0.10019, Val Logloss = 0.23535\n",
      "Epoch 36: Train Logloss = 0.09710, Val Logloss = 0.23032\n",
      "Epoch 37: Train Logloss = 0.09616, Val Logloss = 0.23410\n",
      "Epoch 38: Train Logloss = 0.09386, Val Logloss = 0.23379\n",
      "Epoch 39: Train Logloss = 0.09270, Val Logloss = 0.23355\n",
      "Epoch 40: Train Logloss = 0.09185, Val Logloss = 0.23490\n",
      "Epoch 41: Train Logloss = 0.09032, Val Logloss = 0.23426\n",
      "Epoch 42: Train Logloss = 0.08980, Val Logloss = 0.23214\n",
      "Epoch 43: Train Logloss = 0.08925, Val Logloss = 0.23445\n",
      "Epoch 44: Train Logloss = 0.08805, Val Logloss = 0.23572\n",
      "Epoch 45: Train Logloss = 0.08727, Val Logloss = 0.23726\n",
      "Epoch 46: Train Logloss = 0.08684, Val Logloss = 0.23747\n",
      "Epoch 47: Train Logloss = 0.08650, Val Logloss = 0.23889\n",
      "Epoch 48: Train Logloss = 0.08653, Val Logloss = 0.23789\n",
      "Epoch 49: Train Logloss = 0.08641, Val Logloss = 0.23858\n",
      "Epoch 50: Train Logloss = 0.08641, Val Logloss = 0.23823\n",
      "Early stopping at epoch 50\n",
      "Loading best model from epoch 11 with Logloss 0.18342\n",
      "Training time: 00:00:10\n",
      "Best Logloss: 0.18342\n"
     ]
    }
   ],
   "source": [
    "# Create OOF and test predictions\n",
    "importlib.reload(cv)\n",
    "tr_df8 = tr_df8[:10000]\n",
    "test_df8 = test_df8[:1000]\n",
    "params = {\n",
    "    \"num_layers\": 3,\n",
    "    \"hidden_dim1\": 352,\n",
    "    \"hidden_dim2\": 256,\n",
    "    \"hidden_dim3\": 224,\n",
    "    \"hidden_dim4\": 128,\n",
    "    \"batch_size\": 896,\n",
    "    \"lr\": 0.016867490361457304,\n",
    "    \"eta_min\": 3.9793716038378347e-05,\n",
    "    \"dropout_rate\": 0.35,\n",
    "    \"activation\": \"GELU\"\n",
    "}\n",
    "trainer = cv.MLPCVTrainer(**params)\n",
    "trainer.fit_one_fold(tr_df8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d9c3744-be45-4f44-829a-693a1a346065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.named_parameters at 0x7f02dda5c040>\n"
     ]
    }
   ],
   "source": [
    "model = trainer.fold_models[0].model\n",
    "print(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff542d6a-0856-44a5-b24d-b36daf2aef87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_layers.job.weight\n",
      "embedding_layers.marital.weight\n",
      "embedding_layers.education.weight\n",
      "embedding_layers.default.weight\n",
      "embedding_layers.housing.weight\n",
      "embedding_layers.loan.weight\n",
      "embedding_layers.contact.weight\n",
      "embedding_layers.month.weight\n",
      "embedding_layers.poutcome.weight\n",
      "net.0.weight\n",
      "net.0.bias\n",
      "net.1.weight\n",
      "net.1.bias\n",
      "net.4.weight\n",
      "net.4.bias\n",
      "net.5.weight\n",
      "net.5.bias\n",
      "net.8.weight\n",
      "net.8.bias\n",
      "net.9.weight\n",
      "net.9.bias\n",
      "net.12.weight\n",
      "net.12.bias\n",
      "net.13.weight\n",
      "net.13.bias\n",
      "net.16.weight\n",
      "net.16.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-2.2.0",
   "language": "python",
   "name": "torch22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
