{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0310ea3f-39d4-4522-bfd2-303c8c76fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import src.models.mlp.mlp_cv_trainer as cv\n",
    "import src.utils.optuna_visualizer as opv\n",
    "import src.utils.telegram as te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0483e9a2-ecc5-4078-a62a-31ab26efcca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "env_path = Path.cwd().parent / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "url = os.environ.get(\"OPTUNA_STORAGE_URL\")\n",
    "\n",
    "tr_df1 = pd.read_parquet(\"../artifacts/features/base/tr_df1.parquet\")\n",
    "test_df1 = pd.read_parquet(\"../artifacts/features/base/test_df1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c9d4efe-b5a7-4f62-8a0e-7875dc414dd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot evaluate parameter importances with only a single trial.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m study_name = \u001b[33m\"\u001b[39m\u001b[33mmlp_v3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m study = opv.OptunaVisualizer(study_name, url)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m study.visualize_optimization()\n\u001b[32m      6\u001b[39m study.print_trials_table()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/kaggle/binary-bank/src/utils/optuna_visualizer.py:36\u001b[39m, in \u001b[36mOptunaVisualizer.visualize_optimization\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m探索結果を可視化する関数。\u001b[39;00m\n\u001b[32m     28\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m \u001b[33;03m- パラメータの相互関係\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# パラメータ重要度\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m fig1 = vis.plot_param_importances(\u001b[38;5;28mself\u001b[39m.study)\n\u001b[32m     37\u001b[39m fig1.show()\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# 最適化履歴\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch22/lib/python3.11/site-packages/optuna/visualization/_param_importances.py:168\u001b[39m, in \u001b[36mplot_param_importances\u001b[39m\u001b[34m(study, evaluator, params, target, target_name)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Plot hyperparameter importances.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m    123\u001b[39m \u001b[33;03m.. seealso::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    164\u001b[39m \u001b[33;03m    A :class:`plotly.graph_objects.Figure` object.\u001b[39;00m\n\u001b[32m    165\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    167\u001b[39m _imports.check()\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m importances_infos = _get_importances_infos(study, evaluator, params, target, target_name)\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _get_importances_plot(importances_infos, study)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch22/lib/python3.11/site-packages/optuna/visualization/_param_importances.py:82\u001b[39m, in \u001b[36m_get_importances_infos\u001b[39m\u001b[34m(study, evaluator, params, target, target_name)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m study._is_multi_objective():\n\u001b[32m     80\u001b[39m     target_name = metric_names[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m metric_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m target \u001b[38;5;28;01melse\u001b[39;00m target_name\n\u001b[32m     81\u001b[39m     importances_infos: \u001b[38;5;28mtuple\u001b[39m[_ImportancesInfo, ...] = (\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m         _get_importances_info(\n\u001b[32m     83\u001b[39m             study,\n\u001b[32m     84\u001b[39m             evaluator,\n\u001b[32m     85\u001b[39m             params,\n\u001b[32m     86\u001b[39m             target=target,\n\u001b[32m     87\u001b[39m             target_name=target_name,\n\u001b[32m     88\u001b[39m         ),\n\u001b[32m     89\u001b[39m     )\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     92\u001b[39m     n_objectives = \u001b[38;5;28mlen\u001b[39m(study.directions)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch22/lib/python3.11/site-packages/optuna/visualization/_param_importances.py:54\u001b[39m, in \u001b[36m_get_importances_info\u001b[39m\u001b[34m(study, evaluator, params, target, target_name)\u001b[39m\n\u001b[32m     46\u001b[39m     logger.warning(\u001b[33m\"\u001b[39m\u001b[33mStudy instance does not contain completed trials.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _ImportancesInfo(\n\u001b[32m     48\u001b[39m         importance_values=[],\n\u001b[32m     49\u001b[39m         param_names=[],\n\u001b[32m     50\u001b[39m         importance_labels=[],\n\u001b[32m     51\u001b[39m         target_name=target_name,\n\u001b[32m     52\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m importances = optuna.importance.get_param_importances(\n\u001b[32m     55\u001b[39m     study, evaluator=evaluator, params=params, target=target\n\u001b[32m     56\u001b[39m )\n\u001b[32m     58\u001b[39m importances = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(importances.items())))\n\u001b[32m     59\u001b[39m importance_values = \u001b[38;5;28mlist\u001b[39m(importances.values())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch22/lib/python3.11/site-packages/optuna/importance/__init__.py:111\u001b[39m, in \u001b[36mget_param_importances\u001b[39m\u001b[34m(study, evaluator, params, target, normalize)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evaluator, BaseImportanceEvaluator):\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mEvaluator must be a subclass of BaseImportanceEvaluator.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m res = evaluator.evaluate(study, params=params, target=target)\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[32m    113\u001b[39m     s = \u001b[38;5;28msum\u001b[39m(res.values())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch22/lib/python3.11/site-packages/optuna/importance/_fanova/_evaluator.py:89\u001b[39m, in \u001b[36mFanovaImportanceEvaluator.evaluate\u001b[39m\u001b[34m(self, study, params, target)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m study._is_multi_objective():\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     84\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf the `study` is being used for multi-objective optimization, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     85\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mplease specify the `target`. For example, use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     86\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`target=lambda t: t.values[0]` for the first objective value.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     87\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m distributions = _get_distributions(study, params=params)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     91\u001b[39m     params = \u001b[38;5;28mlist\u001b[39m(distributions.keys())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch22/lib/python3.11/site-packages/optuna/importance/_base.py:74\u001b[39m, in \u001b[36m_get_distributions\u001b[39m\u001b[34m(study, params)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_distributions\u001b[39m(study: Study, params: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseDistribution]:\n\u001b[32m     73\u001b[39m     completed_trials = study.get_trials(deepcopy=\u001b[38;5;28;01mFalse\u001b[39;00m, states=(TrialState.COMPLETE,))\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     _check_evaluate_args(completed_trials, params)\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m intersection_search_space(study.get_trials(deepcopy=\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch22/lib/python3.11/site-packages/optuna/importance/_base.py:119\u001b[39m, in \u001b[36m_check_evaluate_args\u001b[39m\u001b[34m(completed_trials, params)\u001b[39m\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot evaluate parameter importances without completed trials.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(completed_trials) == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot evaluate parameter importances with only a single trial.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(params, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[31mValueError\u001b[39m: Cannot evaluate parameter importances with only a single trial."
     ]
    }
   ],
   "source": [
    "# Check tuning results\n",
    "study_name = \"mlp_v3\"\n",
    "\n",
    "study = opv.OptunaVisualizer(study_name, url)\n",
    "study.visualize_optimization()\n",
    "study.print_trials_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e836cd54-1420-42d6-92fc-db92689d9d8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create OOF and test predictions\n",
    "importlib.reload(cv)\n",
    "params = {\n",
    "    \"hidden_dim1\": 480,\n",
    "    \"hidden_dim2\": 448,\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 0.0005545707560434345,\n",
    "    \"dropout_rate\": 0.05,\n",
    "    \"activation\": \"ReLU\"\n",
    "}\n",
    "trainer = cv.MLPCVTrainer(**params)\n",
    "\n",
    "oof, test_preds = trainer.fit(tr_df1, test_df1)\n",
    "np.save(\"../artifacts/preds/base/oof_single_1.npy\", oof)\n",
    "np.save(\"../artifacts/preds/base/test_single_1.npy\", test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b9ca75-d4bb-444a-a694-d0295bb6ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "te.send_telegram_message(\"MLP Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-2.2.0",
   "language": "python",
   "name": "torch22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
